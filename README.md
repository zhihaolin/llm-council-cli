# LLM Council

[![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://github.com/zhihaolin/llm-council-cli/actions/workflows/test.yml/badge.svg)](https://github.com/zhihaolin/llm-council-cli/actions/workflows/test.yml)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)

**Multi-model deliberation for better answers.**

A system where AI models debate, critique, and synthesize answers together.

Instead of asking one LLM and hoping for the best, LLM Council orchestrates multiple frontier models through structured deliberationâ€”producing more accurate, nuanced, and well-reasoned answers.

![Chairman synthesis after multi-round debate](images/hero.png)

## Why This Exists

Single-model responses have blind spots. LLM Council fixes this by:

1. **Consulting multiple models** â€” GPT, Claude, Gemini, Grok, and DeepSeek all weigh in
2. **Anonymous peer review** â€” Models rank each other's responses without knowing who wrote what (prevents favoritism)
3. **Structured debate** â€” Models critique and defend positions across multiple rounds
4. **Chairman synthesis** â€” A designated model synthesizes the collective wisdom into one answer

The result? Answers that capture the best insights from each model while filtering out individual weaknesses.

---

## Features

### Multi-Model Deliberation

Query your council models in parallel. Each provides an independent response, then anonymously evaluates the others. A chairman model synthesizes the final answer based on the full deliberation.

```
Stage 1: Independent Responses    â†’  Council models answer your question
Stage 2: Anonymous Peer Review    â†’  Each model ranks the others (blind)
Stage 3: Chairman Synthesis       â†’  Best insights combined into final answer
```

### Debate Mode

For complex or controversial questions, enable multi-round debate where models critique each other's reasoning and defend their positions.

```bash
llm-council --debate "Is capitalism or socialism better for reducing poverty?"
llm-council --debate --rounds 3 "Should AI development be paused?"
```

```
Round 1: Initial Responses    â†’  Each model presents their position
Round 2: Critiques            â†’  Models challenge each other's arguments
Round 3: Defense & Revision   â†’  Models defend valid points, concede weaknesses
Final:   Chairman Synthesis   â†’  Synthesizes the evolved positions
```

![Models critiquing each other in debate mode](images/debate.png)

### Autonomous Web Search

Models decide when they need current information. No manual flagsâ€”they call the search tool when the question requires it.

```bash
llm-council "What is the current price of Bitcoin?"
# Models automatically search for real-time data
```

The CLI shows which models used search with a `[searched]` indicator on each panel. When ReAct reasoning is enabled (default), panels also show `[reasoned]`.

**Search-enabled rounds in debate mode:**
- Round 1 (Initial): Models search to gather facts for their position
- Round 3 (Defense): Models search to find evidence supporting their defense

![Models autonomously searching for current information](images/search.png)

### Chairman Reflection

The chairman deeply analyzes all model responses before synthesizing. It identifies areas of agreement, disagreement, and factual claims that warrant scrutinyâ€”then produces a well-reasoned final answer.

```
â”â”â” CHAIRMAN'S REFLECTION â”â”â”

â”Œâ”€ Reflection â€¢ gemini-2.5-pro â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Areas of agreement: All models agree that...          â”‚
â”‚ Areas of disagreement: GPT claims X while Claude...   â”‚
â”‚ Factual claims to verify: The price cited by...       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ Final Answer â€¢ gemini-2.5-pro â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Synthesized answer]                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Council ReAct

Council members use ReAct (Reasoning + Acting) to decide when to search for current information. Their reasoning is visible in streaming mode.

```
  gpt-4.1 thought: The question asks about current prices. I should verify.
  gpt-4.1 search: "bitcoin price today"
  Bitcoin is currently trading at $67,234...
  gpt-4.1: Based on my research, Bitcoin is currently...
```

ReAct is enabled by default for council members. Disable with `--no-react` or `/react off` in chat mode.

### Interactive Chat Mode

Multi-turn conversations with persistent history. The chat REPL remembers context and lets you switch between ranking and debate modes on the fly.

```bash
uv run llm-council chat
```

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Council Chat  Â·  abc12345  Â·  Resumed
  Mode: Debate Â· 2 rounds Â· React on Â· Stream off
  Commands: /new /history /use <id> Â· /debate /rounds /stream /react Â· /mode /help /exit
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

council> What is the capital of France?
```

Slash commands:
- **Session:** `/new`, `/history`, `/use <id>`
- **Config:** `/debate on|off`, `/rounds N`, `/stream on|off`, `/react on|off`
- **Info:** `/mode`, `/help`, `/exit`

### Rich Terminal Interface

- **CLI mode** â€” Full 3-stage output with progress indicators
- **Simple mode** â€” Just the final answer, pipe-friendly
- **Chat mode** â€” Interactive REPL with conversation history

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Query                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 1: Parallel Model Queries                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Model A â”‚ â”‚ Model B â”‚ â”‚ Model C â”‚ â”‚ Model D â”‚ â”‚ Model E â”‚   â”‚
â”‚  â”‚  (GPT)  â”‚ â”‚(Gemini) â”‚ â”‚(Claude) â”‚ â”‚ (Grok)  â”‚ â”‚(DeepSeek)   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚           â”‚           â”‚           â”‚           â”‚         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                         â”‚                                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚              â”‚   Web Search Tool   â”‚  (Tavily API)              â”‚
â”‚              â”‚  Models call when   â”‚                            â”‚
â”‚              â”‚  they need current  â”‚                            â”‚
â”‚              â”‚    information      â”‚                            â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 2: Anonymous Peer Review                      â”‚
â”‚                                                                  â”‚
â”‚   Responses anonymized as "Response A, B, C, D, E"              â”‚
â”‚   Each model ranks all responses (can't identify authors)        â”‚
â”‚   Aggregate rankings computed from all evaluations               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Stage 3: Chairman Synthesis                         â”‚
â”‚                                                                  â”‚
â”‚   Chairman model receives:                                       â”‚
â”‚   - All original responses                                       â”‚
â”‚   - All peer evaluations                                         â”‚
â”‚   - Aggregate rankings                                           â”‚
â”‚                                                                  â”‚
â”‚   Produces: Single comprehensive answer                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Debate Mode Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Round 1: Initial        Round 2: Critique       Round 3: Defend â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Modelâ”‚ â”‚Modelâ”‚   â†’    â”‚  A  â”‚â†’â”‚  B  â”‚   â†’    â”‚Reviseâ”‚ â”‚Reviseâ”‚ â”‚
â”‚  â”‚  A  â”‚ â”‚  B  â”‚        â”‚critiques B,C,Dâ”‚        â”‚  A   â”‚ â”‚  B   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Modelâ”‚ â”‚Modelâ”‚   â†’    â”‚  C  â”‚â†’â”‚  D  â”‚   â†’    â”‚Reviseâ”‚ â”‚Reviseâ”‚ â”‚
â”‚  â”‚  C  â”‚ â”‚  D  â”‚        â”‚critiques A,B,Dâ”‚        â”‚  C   â”‚ â”‚  D   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Chairman     â”‚
                    â”‚   Synthesizes   â”‚
                    â”‚  Full Debate    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Start

### Option A: Docker (Recommended)

```bash
# Build once
docker build -t llm-council https://github.com/zhihaolin/llm-council-cli.git

# Run
docker run -e OPENROUTER_API_KEY=your-key llm-council query "What is 2+2?"

# With web search
docker run -e OPENROUTER_API_KEY=your-key -e TAVILY_API_KEY=your-key \
  llm-council query "What is the current price of Bitcoin?"

# Debate mode
docker run -e OPENROUTER_API_KEY=your-key llm-council query --debate "Should AI be regulated?"
```

### Option B: Local Install

```bash
git clone https://github.com/zhihaolin/llm-council-cli.git
cd llm-council-cli

# Install uv if you don't have it
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies
uv sync

# Configure API keys
echo "OPENROUTER_API_KEY=sk-or-v1-your-key-here" > .env
echo "TAVILY_API_KEY=tvly-your-key-here" >> .env  # Optional, for web search

# Run
uv run llm-council query "What is the best programming language for beginners?"
```

Get your API keys:
- [openrouter.ai](https://openrouter.ai/) â€” Required, provides access to GPT, Claude, Gemini, etc.
- [tavily.com](https://tavily.com/) â€” Optional, enables web search (free tier: 1000 searches/month)

---

## CLI Usage

### Commands

```bash
# Query with full deliberation output
uv run llm-council query "Your question"

# Query with debate mode
uv run llm-council query --debate "Complex question"
uv run llm-council query --debate --rounds 3 "Very complex question"

# Simple output (final answer only, no stages)
uv run llm-council query --simple "Quick question"

# Final answer with formatting (skip stages 1 & 2)
uv run llm-council query --final-only "Question"

# Show current council configuration
uv run llm-council models

# Interactive chat with history
uv run llm-council chat
uv run llm-council chat --new  # Start fresh conversation
```

### Flags

| Flag | Short | Description |
|------|-------|-------------|
| `--simple` | `-s` | Output only the final answer (no formatting) |
| `--final-only` | `-f` | Show only chairman's synthesis (with formatting) |
| `--debate` | `-d` | Enable debate mode |
| `--rounds N` | `-r N` | Number of critique-defense cycles (default: 1) |
| `--stream` | | Stream token-by-token (sequential, debate mode) |
| `--no-react` | | Disable council ReAct reasoning (use native function calling) |
| `--new` | | Start a new conversation (chat mode) |
| `--max-turns N` | `-t N` | Context turns to include (chat mode, default: 6) |

---

## Configuration

### Models

Edit `config.yaml` in the project root to customize the council:

```yaml
# Council models - list of OpenRouter model identifiers
council_models:
  - openai/gpt-4o-mini      # Fast, cost-effective
  - x-ai/grok-3             # X.AI's latest
  - deepseek/deepseek-chat  # Strong reasoning

# Chairman model - synthesizes the final response
chairman_model: openai/gpt-4o-mini
```

All models are accessed through [OpenRouter](https://openrouter.ai/), which provides a unified API for 200+ models from OpenAI, Anthropic, Google, Meta, and more. Choose models based on your budget and quality requirements.

**Docker users:** Mount a custom config with `-v /path/to/config.yaml:/app/config.yaml`

---

## Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | Python 3.10+, async httpx |
| CLI | Typer, Rich |
| LLM Access | OpenRouter API (unified access to GPT, Claude, Gemini, etc.) |
| Web Search | Tavily API (LLM-optimized search) |
| Testing | pytest, pytest-asyncio |
| Storage | JSON files |

---

## Engineering Practices

| Practice | Status | Details |
|----------|--------|---------|
| **Async/Parallel** | âœ… | Concurrent API calls with `asyncio.gather()` |
| **Graceful Degradation** | âœ… | Continues if individual models fail |
| **Test Suite** | âœ… | pytest + pytest-asyncio, 108 tests |
| **Linting** | âœ… | Ruff (check + format) in CI |
| **Type Checking** | âœ… | Pyright in basic mode |
| **Type Hints** | âœ… | Throughout codebase |
| **CI/CD** | âœ… | GitHub Actions (lint â†’ test â†’ docker pipeline) |
| **SOLID (SRP/ISP)** | âœ… | Focused modules, clean API exports |
| **Pydantic Models** | ğŸ”œ | Data validation (planned) |
| **Structured Logging** | ğŸ”œ | JSON logs with correlation IDs (planned) |
| **Config Management** | âœ… | YAML config file (`config.yaml`) |

See [docs/PLAN.md](docs/PLAN.md) for the full engineering roadmap.

---

## Development

### Running Tests

```bash
# Install dev dependencies
uv sync --extra dev

# Run all tests
uv run pytest tests/ -v
```

### Test Structure

```
tests/
â”œâ”€â”€ conftest.py                  # Fixtures and mock API responses
â”œâ”€â”€ test_chat_commands.py        # Chat REPL + model panel indicators (11 tests)
â”œâ”€â”€ test_cli_imports.py          # CLI smoke test (1 test)
â”œâ”€â”€ test_conversation_context.py # Context extraction (5 tests)
â”œâ”€â”€ test_debate.py               # Debate mode + RoundConfig + ReAct (24 tests)
â”œâ”€â”€ test_ranking_parser.py       # Ranking extraction (14 tests)
â”œâ”€â”€ test_react.py                # ReAct parsing & council loop (12 tests)
â”œâ”€â”€ test_reflection.py           # Chairman Reflection parsing & loop (6 tests)
â”œâ”€â”€ test_search.py               # Web search & tool calling (18 tests)
â”œâ”€â”€ test_streaming.py            # Streaming & parallel (17 tests)
â””â”€â”€ integration/                 # CLI integration tests (planned)
```

---

## Roadmap

| Version | Feature | Status |
|---------|---------|--------|
| v1.0 | CLI | âœ… Complete |
| v1.1 | Autonomous Web Search | âœ… Complete |
| v1.2 | Multi-Turn Debate Mode | âœ… Complete |
| v1.3 | Interactive Chat with History | âœ… Complete |
| v1.4 | Token Streaming | âœ… Complete |
| v1.5 | Parallel Execution with Progress | âœ… Complete |
| v1.6 | ReAct Chairman | âœ… Complete |
| v1.6.1 | SOLID Refactoring | âœ… Complete |
| v1.6.2 | CI Quality Gates (ruff, pyright) | âœ… Complete |
| v1.6.3 | Docker Support | âœ… Complete |
| v1.7 | Unify Debate Logic | âœ… Complete |
| v1.8 | Rename Debate Functions | âœ… Complete |
| v1.9 | Strategy Pattern (OCP/DIP) | âœ… Complete |
| Post-v1.9 | Chairman Reflection + Council ReAct | âœ… Complete |
| Post-v1.9 | Chat UI Improvements | âœ… Complete |
| v1.10 | Self-Reflection Round | Planned |
| v1.11 | Workflow State Machine | Planned |
| v1.12 | Human-in-the-Loop (HITL) | Planned |
| v1.13 | Observability (OpenTelemetry) | Planned |
| v1.14 | Tool Registry (MCP) | Planned |
| v1.15 | Retry & Fallback Logic | Planned |
| v1.16 | Security Foundations | Planned |

See [docs/PLAN.md](docs/PLAN.md) for the full roadmap and [docs/DEVLOG.md](docs/DEVLOG.md) for development history.

---

## Credits

This project builds upon the original [LLM Council](https://github.com/karpathy/llm-council) concept by **[Andrej Karpathy](https://github.com/karpathy)**. The core idea of using multiple LLMs with peer review comes from his work.

This fork extends the original with:
- Full CLI interface
- Interactive chat with conversation history
- Autonomous web search via tool calling
- Multi-turn debate mode
- Chairman Reflection + Council ReAct reasoning
- Rich terminal output with progress indicators

---

## License

MIT
